{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 5: Vehicle Detection and Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image paths and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your function returned a count of 4050  cars and 8968  non-cars\n",
      "of size:  (64, 64, 3)  and data type: float32\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from skimage.feature import hog\n",
    "from skimage import color, exposure\n",
    "%matplotlib inline\n",
    "\n",
    "# images are divided up into vehicles and non-vehicles\n",
    "car_images_udacity = glob.glob(r'C:\\Users\\mohar\\Desktop\\Udacity\\vehicles\\*\\*.png')\n",
    "notcar_images_udacity = glob.glob(r'C:\\Users\\mohar\\Desktop\\Udacity\\non-vehicles\\*\\*.png')\n",
    "\n",
    "cars = []\n",
    "notcars = []\n",
    "\n",
    "for image in car_images_udacity:\n",
    "    cars.append(image)\n",
    "\n",
    "for image in notcar_images_udacity:\n",
    "    notcars.append(image)\n",
    "        \n",
    "# Define a function to return some characteristics of the dataset \n",
    "def data_look(car_list, notcar_list):\n",
    "    data_dict = {}\n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(car_list)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(notcar_list)\n",
    "    # Read in a test image, either car or notcar\n",
    "    test_img = mpimg.imread(car_list[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = test_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = test_img.dtype\n",
    "    # Return data_dict\n",
    "    return data_dict\n",
    "    \n",
    "data_info = data_look(cars, notcars)\n",
    "\n",
    "print('Your function returned a count of', \n",
    "      data_info[\"n_cars\"], ' cars and', \n",
    "      data_info[\"n_notcars\"], ' non-cars')\n",
    "print('of size: ',data_info[\"image_shape\"], ' and data type:', \n",
    "      data_info[\"data_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the number of notcar images is more than car images we augment the car class using crowdai's dataset. The images from crowdai's dataset have been cropped as per bounding boxes and resized to (64, 64, 3). The processed images are stored in a folder called resized. The code can be found in Augment_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_images_crowdai = glob.glob(r'C:\\Users\\mohar\\Desktop\\Udacity\\Self-Driving-Car-NanoDegree-Udacity\\\\\n",
    "Term1-Computer-Vision-and-Deep-Learning\\Project5-Vehicle-Detection-and-Tracking\\resized\\*.jpg')\n",
    "# load image path randomly from resized images to augment car class\n",
    "for i in range(len(notcars) - len(cars)):\n",
    "        np.random.seed(0) # generate same random numbers everytime to avoid issues due to variation in training data later\n",
    "        cars.append(np.random.randint(0, len(car_images_crowdai)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that each class has equal number of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your function returned a count of 8968  cars and 8968  non-cars\n",
      "of size:  (64, 64, 3)  and data type: float32\n"
     ]
    }
   ],
   "source": [
    "data_info = data_look(cars, notcars)\n",
    "\n",
    "print('Your function returned a count of', \n",
    "      data_info[\"n_cars\"], ' cars and', \n",
    "      data_info[\"n_notcars\"], ' non-cars')\n",
    "print('of size: ',data_info[\"image_shape\"], ' and data type:', \n",
    "      data_info[\"data_type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs, cspace='RGB', spatial_size=(16, 16), hist_bins=32, hist_range=(0, 256),\n",
    "                     norient=9, hog_pix_cell=(8, 8), hog_cell_block=(2,2)):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        else: feature_image = np.copy(image)      \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() to get histogram color features\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        # Apply get_hog_features() to get hog features\n",
    "        hog_features = get_hog_features(feature_image, orient=norient, pix_per_cell=hog_pix_cell,\n",
    "                                         cell_per_block=hog_cell_block)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features, hog_features)))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a classifier using linear support vector machine (svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
